# Misconception Detection in Student Short Answers

This project explores **automatic misconception detection** in student open-ended responses using the **SciEntsBank dataset**.  
By combining **state-of-the-art NLP models** (BERT, DeBERTa, LLaMA) with **explainable AI techniques** (SHAP).
This project aims to:

- ðŸ“– Classify student answers into *Correct, Partially Correct, Incorrect, Irrelevant*.  
- ðŸ”Ž Identify common **misconception patterns** across student populations.  
- ðŸ§© Provide **interpretable explanations** for model predictions to support teachers and researchers.  

### âœ¨ Key Features
- Fine-tuned transformer-based models (BERT, DeBERTa, LLaMA) for short answer classification.  
- Misconception clustering and visualization to highlight common learning difficulties.  
- Explainability via SHAP for transparent feedback.  
- Jupyter notebooks for reproducibility and easy experimentation.  

### ðŸŽ¯ Motivation
Most EdTech systems provide only "right/wrong" judgments, but teachers and students need deeper insights into **why mistakes happen**.  
This project bridges **educational science** and **data science** by uncovering student misconceptions and making model decisions transparent.  

### ðŸš€ Future Work
- Integrating Reinforcement Learning for adaptive feedback.  
- Building a dashboard for teachers to visualize misconceptions.  




## ðŸ“œ License
This repository is licensed under the **Creative Commons Attribution-NonCommercial 4.0 International License (CC BY-NC 4.0)**.  
You may use this work for **research and educational purposes only**.  
ðŸ‘‰ [View full license here](https://creativecommons.org/licenses/by-nc/4.0/)
